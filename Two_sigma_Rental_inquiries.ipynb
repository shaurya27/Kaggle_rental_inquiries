{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Sigma Connect: Rental Listing Inquiries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a machine learning model, built on a Scikit-learn framework, to attempt to solve the [Two Sigma Connect: Rental Listing Inquiries](https://www.kaggle.com/c/two-sigma-connect-rental-listing-inquiries) on [Kaggle](https://www.kaggle.com/). This project was begun by Shaurya Shubham on June 6, 2017,after the competition was completed. In this project he did a peform a feature engineering and stacink of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things I learnt from this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How to make Likelihood feature, which is a Secret Recipe's of Kaggle's GrandMaster.\n",
    "* How to combine model using Voting-Classifier and Stacking and Essembling.\n",
    "* How to overcome to frustaion and not to give up spirit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaurya\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading Datasets\n",
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making a copy of datasets\n",
    "train_ = train\n",
    "test_ = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49352, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>interest_level</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>manager_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>price</th>\n",
       "      <th>street_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53a5b119ba8f7b61d4e010512e0dfc85</td>\n",
       "      <td>2016-06-24 07:54:24</td>\n",
       "      <td>A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...</td>\n",
       "      <td>Metropolitan Avenue</td>\n",
       "      <td>[]</td>\n",
       "      <td>medium</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>7211212</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>5ba989232d0489da1b5f2c45f6688adc</td>\n",
       "      <td>[https://photos.renthop.com/2/7211212_1ed4542e...</td>\n",
       "      <td>3000</td>\n",
       "      <td>792 Metropolitan Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>c5c8a357cba207596b04d1afd1e4f130</td>\n",
       "      <td>2016-06-12 12:19:27</td>\n",
       "      <td></td>\n",
       "      <td>Columbus Avenue</td>\n",
       "      <td>[Doorman, Elevator, Fitness Center, Cats Allow...</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7947</td>\n",
       "      <td>7150865</td>\n",
       "      <td>-73.9667</td>\n",
       "      <td>7533621a882f71e25173b27e3139d83d</td>\n",
       "      <td>[https://photos.renthop.com/2/7150865_be3306c5...</td>\n",
       "      <td>5465</td>\n",
       "      <td>808 Columbus Avenue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>c3ba40552e2120b0acfc3cb5730bb2aa</td>\n",
       "      <td>2016-04-17 03:26:41</td>\n",
       "      <td>Top Top West Village location, beautiful Pre-w...</td>\n",
       "      <td>W 13 Street</td>\n",
       "      <td>[Laundry In Building, Dishwasher, Hardwood Flo...</td>\n",
       "      <td>high</td>\n",
       "      <td>40.7388</td>\n",
       "      <td>6887163</td>\n",
       "      <td>-74.0018</td>\n",
       "      <td>d9039c43983f6e564b1482b273bd7b01</td>\n",
       "      <td>[https://photos.renthop.com/2/6887163_de85c427...</td>\n",
       "      <td>2850</td>\n",
       "      <td>241 W 13 Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100007</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>28d9ad350afeaab8027513a3e52ac8d5</td>\n",
       "      <td>2016-04-18 02:22:02</td>\n",
       "      <td>Building Amenities - Garage - Garden - fitness...</td>\n",
       "      <td>East 49th Street</td>\n",
       "      <td>[Hardwood Floors, No Fee]</td>\n",
       "      <td>low</td>\n",
       "      <td>40.7539</td>\n",
       "      <td>6888711</td>\n",
       "      <td>-73.9677</td>\n",
       "      <td>1067e078446a7897d2da493d2f741316</td>\n",
       "      <td>[https://photos.renthop.com/2/6888711_6e660cee...</td>\n",
       "      <td>3275</td>\n",
       "      <td>333 East 49th Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100013</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-28 01:32:41</td>\n",
       "      <td>Beautifully renovated 3 bedroom flex 4 bedroom...</td>\n",
       "      <td>West 143rd Street</td>\n",
       "      <td>[Pre-War]</td>\n",
       "      <td>low</td>\n",
       "      <td>40.8241</td>\n",
       "      <td>6934781</td>\n",
       "      <td>-73.9493</td>\n",
       "      <td>98e13ad4b495b9613cef886d79a6291f</td>\n",
       "      <td>[https://photos.renthop.com/2/6934781_1fa4b41a...</td>\n",
       "      <td>3350</td>\n",
       "      <td>500 West 143rd Street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bathrooms  bedrooms                       building_id  \\\n",
       "10            1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   \n",
       "10000         1.0         2  c5c8a357cba207596b04d1afd1e4f130   \n",
       "100004        1.0         1  c3ba40552e2120b0acfc3cb5730bb2aa   \n",
       "100007        1.0         1  28d9ad350afeaab8027513a3e52ac8d5   \n",
       "100013        1.0         4                                 0   \n",
       "\n",
       "                    created  \\\n",
       "10      2016-06-24 07:54:24   \n",
       "10000   2016-06-12 12:19:27   \n",
       "100004  2016-04-17 03:26:41   \n",
       "100007  2016-04-18 02:22:02   \n",
       "100013  2016-04-28 01:32:41   \n",
       "\n",
       "                                              description  \\\n",
       "10      A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   \n",
       "10000                                                       \n",
       "100004  Top Top West Village location, beautiful Pre-w...   \n",
       "100007  Building Amenities - Garage - Garden - fitness...   \n",
       "100013  Beautifully renovated 3 bedroom flex 4 bedroom...   \n",
       "\n",
       "            display_address  \\\n",
       "10      Metropolitan Avenue   \n",
       "10000       Columbus Avenue   \n",
       "100004          W 13 Street   \n",
       "100007     East 49th Street   \n",
       "100013    West 143rd Street   \n",
       "\n",
       "                                                 features interest_level  \\\n",
       "10                                                     []         medium   \n",
       "10000   [Doorman, Elevator, Fitness Center, Cats Allow...            low   \n",
       "100004  [Laundry In Building, Dishwasher, Hardwood Flo...           high   \n",
       "100007                          [Hardwood Floors, No Fee]            low   \n",
       "100013                                          [Pre-War]            low   \n",
       "\n",
       "        latitude  listing_id  longitude                        manager_id  \\\n",
       "10       40.7145     7211212   -73.9425  5ba989232d0489da1b5f2c45f6688adc   \n",
       "10000    40.7947     7150865   -73.9667  7533621a882f71e25173b27e3139d83d   \n",
       "100004   40.7388     6887163   -74.0018  d9039c43983f6e564b1482b273bd7b01   \n",
       "100007   40.7539     6888711   -73.9677  1067e078446a7897d2da493d2f741316   \n",
       "100013   40.8241     6934781   -73.9493  98e13ad4b495b9613cef886d79a6291f   \n",
       "\n",
       "                                                   photos  price  \\\n",
       "10      [https://photos.renthop.com/2/7211212_1ed4542e...   3000   \n",
       "10000   [https://photos.renthop.com/2/7150865_be3306c5...   5465   \n",
       "100004  [https://photos.renthop.com/2/6887163_de85c427...   2850   \n",
       "100007  [https://photos.renthop.com/2/6888711_6e660cee...   3275   \n",
       "100013  [https://photos.renthop.com/2/6934781_1fa4b41a...   3350   \n",
       "\n",
       "                 street_address  \n",
       "10      792 Metropolitan Avenue  \n",
       "10000       808 Columbus Avenue  \n",
       "100004          241 W 13 Street  \n",
       "100007     333 East 49th Street  \n",
       "100013    500 West 143rd Street  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing the train datasets\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in train set: 15\n",
      "=================\n",
      "Index(['bathrooms', 'bedrooms', 'building_id', 'created', 'description',\n",
      "       'display_address', 'features', 'interest_level', 'latitude',\n",
      "       'listing_id', 'longitude', 'manager_id', 'photos', 'price',\n",
      "       'street_address'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Let's check the number of columns in train dataset\n",
    "print(\"Number of columns in train set:\", len(train.columns))\n",
    "print('=================')\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in test set: 14\n",
      "=================\n",
      "Index(['bathrooms', 'bedrooms', 'building_id', 'created', 'description',\n",
      "       'display_address', 'features', 'latitude', 'listing_id', 'longitude',\n",
      "       'manager_id', 'photos', 'price', 'street_address'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Let's check the number of columns in test dataset\n",
    "print(\"Number of columns in test set:\", len(test.columns))\n",
    "print('=================')\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "street_address    0\n",
       "price             0\n",
       "photos            0\n",
       "manager_id        0\n",
       "longitude         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values\n",
    "train.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "street_address    0\n",
       "price             0\n",
       "photos            0\n",
       "manager_id        0\n",
       "longitude         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values in ascending order to confir null values present or not\n",
    "test.isnull().sum().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>49352.00000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>4.935200e+04</td>\n",
       "      <td>49352.000000</td>\n",
       "      <td>4.935200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.21218</td>\n",
       "      <td>1.541640</td>\n",
       "      <td>40.741545</td>\n",
       "      <td>7.024055e+06</td>\n",
       "      <td>-73.955716</td>\n",
       "      <td>3.830174e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50142</td>\n",
       "      <td>1.115018</td>\n",
       "      <td>0.638535</td>\n",
       "      <td>1.262746e+05</td>\n",
       "      <td>1.177912</td>\n",
       "      <td>2.206687e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.811957e+06</td>\n",
       "      <td>-118.271000</td>\n",
       "      <td>4.300000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.728300</td>\n",
       "      <td>6.915888e+06</td>\n",
       "      <td>-73.991700</td>\n",
       "      <td>2.500000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.751800</td>\n",
       "      <td>7.021070e+06</td>\n",
       "      <td>-73.977900</td>\n",
       "      <td>3.150000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.774300</td>\n",
       "      <td>7.128733e+06</td>\n",
       "      <td>-73.954800</td>\n",
       "      <td>4.100000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>44.883500</td>\n",
       "      <td>7.753784e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.490000e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bathrooms      bedrooms      latitude    listing_id     longitude  \\\n",
       "count  49352.00000  49352.000000  49352.000000  4.935200e+04  49352.000000   \n",
       "mean       1.21218      1.541640     40.741545  7.024055e+06    -73.955716   \n",
       "std        0.50142      1.115018      0.638535  1.262746e+05      1.177912   \n",
       "min        0.00000      0.000000      0.000000  6.811957e+06   -118.271000   \n",
       "25%        1.00000      1.000000     40.728300  6.915888e+06    -73.991700   \n",
       "50%        1.00000      1.000000     40.751800  7.021070e+06    -73.977900   \n",
       "75%        1.00000      2.000000     40.774300  7.128733e+06    -73.954800   \n",
       "max       10.00000      8.000000     44.883500  7.753784e+06      0.000000   \n",
       "\n",
       "              price  \n",
       "count  4.935200e+04  \n",
       "mean   3.830174e+03  \n",
       "std    2.206687e+04  \n",
       "min    4.300000e+01  \n",
       "25%    2.500000e+03  \n",
       "50%    3.150000e+03  \n",
       "75%    4.100000e+03  \n",
       "max    4.490000e+06  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see some stats of train dataset\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bathrooms       2.560563\n",
       "bedrooms        0.446912\n",
       "latitude      -63.170742\n",
       "listing_id      0.251568\n",
       "longitude      58.964396\n",
       "price         177.694002\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the skewness of the features\n",
    "train.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Making a list of features that will I use in the prediction\n",
    "features_to_use = ['bathrooms', 'bedrooms','latitude', 'longitude','price' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing categorical feature to numerical\n",
    "interest_dict = {'low':0, 'medium':1, 'high':2}\n",
    "train_['interest_level'] = train['interest_level'].map(interest_dict)\n",
    "train_y = train_['interest_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Correcting the Skewness of target variable\n",
    "train_['price']=np.log1p(train['price'])\n",
    "test_['price']=np.log1p(test['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the libraries for model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a basic model on the train datasets to check the resuls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.3280614347\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = DecisionTreeClassifier()\n",
    "results = model_selection.cross_val_score(model, train[features_to_use], train_y, cv=kfold ,scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.01097300945\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model2 = RandomForestClassifier(criterion='entropy')\n",
    "results = model_selection.cross_val_score(model2, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.98275699\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model3 = RandomForestClassifier(criterion='gini')\n",
    "results = model_selection.cross_val_score(model3, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.672688713178\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model4 = GradientBoostingClassifier()\n",
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.663612502704\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "eclf = VotingClassifier(estimators=[\n",
    "    ('model', model), ('model2', model2), ('model3', model3), ('model4', model4)], voting='soft', weights = [1,1,1,3])\n",
    "results = model_selection.cross_val_score(eclf, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add some features to improve the performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"created\"] = pd.to_datetime(train[\"created\"])\n",
    "train[\"created_year\"] = train[\"created\"].dt.year\n",
    "train[\"created_month\"] = train[\"created\"].dt.month\n",
    "train[\"created_day\"] = train[\"created\"].dt.day\n",
    "\n",
    "test[\"created\"] = pd.to_datetime(test[\"created\"])\n",
    "test[\"created_year\"] = test[\"created\"].dt.year\n",
    "test[\"created_month\"] = test[\"created\"].dt.month\n",
    "test[\"created_day\"] = test[\"created\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use.append('created_day')\n",
    "features_to_use.append('created_month')\n",
    "features_to_use.append('created_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"num_features\"] = train[\"features\"].apply(lambda x : len(x))\n",
    "test[\"num_features\"] = test[\"features\"].apply(lambda x : len(x))\n",
    "\n",
    "#train2[\"num_features\"] = train[\"features\"].apply(lambda x : len(x))\n",
    "#test2[\"num_features\"] = test[\"features\"].apply(lambda x : len(x))\n",
    "\n",
    "features_to_use.append('num_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.653540154755\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"num_photos\"] = train[\"photos\"].apply(len)\n",
    "test[\"num_photos\"] = test[\"photos\"].apply(len)\n",
    "\n",
    "#train2[\"num_photos\"] = train[\"photos\"].apply(len)\n",
    "#test2[\"num_photos\"] = test[\"photos\"].apply(len)\n",
    "\n",
    "features_to_use.append('num_photos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the results after some feature enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.640553310004\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's extract some important feature from text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "def length_of_description(raw_description):\n",
    "    \n",
    "    description_text = BeautifulSoup(raw_description, \"html.parser\").get_text() # Remove HTML\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", description_text) # Remove non letters\n",
    "    words = letters_only.lower().split() #Convert to lower case, split into individual words\n",
    "    stops = set(stopwords.words(\"english\")) \n",
    "    meaningful_words = [w for w in words if not w in stops] # Remove stop words\n",
    "    meaningful_words = [w for w in meaningful_words if len(w)>1] # single word if any\n",
    "    return( len( meaningful_words ))\n",
    "\n",
    "def clean_description(raw_description):\n",
    "    \n",
    "    description_text = BeautifulSoup(raw_description, \"html.parser\").get_text() # Remove HTML\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", description_text) # Remove non letters\n",
    "    words = letters_only.lower().split() #Convert to lower case, split into individual words\n",
    "    stops = set(stopwords.words(\"english\")) \n",
    "    meaningful_words = [w for w in words if not w in stops] # Remove stop words\n",
    "    meaningful_words = [w for w in meaningful_words if len(w)>1] # single word if any\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaurya\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "train['clean_description'] = train['description'].apply(lambda x : clean_description(x))\n",
    "test['clean_description'] = test['description'].apply(lambda x : clean_description(x))\n",
    "\n",
    "#train2['clean_description'] = train['description'].apply(lambda x : clean_description(x))\n",
    "#test2['clean_description'] = test['description'].apply(lambda x : clean_description(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaurya\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "# Let's add length of description as a feature\n",
    "train['description_length'] = train['description'].apply(lambda x : length_of_description(x))\n",
    "test['description_length'] = test['description'].apply(lambda x : length_of_description(x))\n",
    "\n",
    "#train2['description_length'] = train['description'].apply(lambda x : length_of_description(x))\n",
    "#test2['description_length'] = test['description'].apply(lambda x : length_of_description(x))\n",
    "\n",
    "features_to_use.append('description_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.639786153295\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now add some more features to further increase the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"price_t\"] =train[\"price\"]/train[\"bedrooms\"]\n",
    "test[\"price_t\"] = test[\"price\"]/test[\"bedrooms\"] \n",
    "\n",
    "train['room_sum'] = train['bedrooms']  + train['bathrooms']\n",
    "test['room_sum'] = test['bedrooms']  + test['bathrooms']\n",
    "\n",
    "train['price_per_room'] = train['price']/train['room_sum']\n",
    "test['price_per_room'] = test['price']/test['room_sum']\n",
    "\n",
    "train['price_per_room'] = train['price_per_room'].apply(lambda x: 0 if x==np.inf else x)\n",
    "test['price_per_room'] = test['price_per_room'].apply(lambda x: 0 if x==np.inf else x)\n",
    "train['price_t'] = train['price_t'].apply(lambda x: 0 if x==np.inf else x)\n",
    "test['price_t'] = test['price_t'].apply(lambda x: 0 if x==np.inf else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2[\"price_t\"] =train[\"price\"]/train[\"bedrooms\"]\n",
    "test2[\"price_t\"] = test[\"price\"]/test[\"bedrooms\"] \n",
    "\n",
    "train2['room_sum'] = train['bedrooms']  + train['bathrooms']\n",
    "test2['room_sum'] = test['bedrooms']  + test['bathrooms']\n",
    "\n",
    "train2['price_per_room'] = train['price']/train['room_sum']\n",
    "test2['price_per_room'] = test['price']/test['room_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['price_per_room'] = train['price_per_room'].apply(lambda x: 0 if x==np.inf else x)\n",
    "test['price_per_room'] = test['price_per_room'].apply(lambda x: 0 if x==np.inf else x)\n",
    "train['price_t'] = train['price_t'].apply(lambda x: 0 if x==np.inf else x)\n",
    "test['price_t'] = test['price_t'].apply(lambda x: 0 if x==np.inf else x)\n",
    "\n",
    "#train2['price_per_room'] = train['price_per_room'].apply(lambda x: 0 if x==np.inf else x)\n",
    "#test2['price_per_room'] = test['price_per_room'].apply(lambda x: 0 if x==np.inf else x)\n",
    "#train2['price_t'] = train['price_t'].apply(lambda x: 0 if x==np.inf else x)\n",
    "#test2['price_t'] = test['price_t'].apply(lambda x: 0 if x==np.inf else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use.append('price_t')\n",
    "features_to_use.append('room_sum')\n",
    "features_to_use.append('price_per_room')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.638719296049\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['price']=np.log1p(train['price'])\n",
    "test2['price']=np.log1p(test['price'])\n",
    "\n",
    "train2['price_per_room']=np.log1p(train['price_per_room'])\n",
    "test2['price_per_room']=np.log1p(test['price_per_room'])\n",
    "\n",
    "train2['price_t']=np.log1p(train['price_t'])\n",
    "test2['price_t']=np.log1p(test['price_t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_selection.cross_val_score(model4, train2[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kfold2 = model_selection.KFold( n_splits =10,  random_state= 12)\n",
    "kfold3 = model_selection.KFold( n_splits =10,  random_state= 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Likelihood features(it's a magic feature) using manager_id and Building_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2 = train[['manager_id','interest_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaurya\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Shaurya\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train2['manager_skill'] =np.nan\n",
    "\n",
    "for train_idx, test_idx in kfold3.split(train2):\n",
    "    trainX, testX = train2.iloc[train_idx], train2.iloc[test_idx]\n",
    "    trainy, testy = train_y.iloc[train_idx], train_y.iloc[test_idx]\n",
    "    \n",
    "\n",
    "    for train_idx2, test_idx2 in kfold3.split(trainX):\n",
    "        trainX2, testX2 = trainX.iloc[train_idx2], trainX.iloc[test_idx2]\n",
    "        trainy2, testy2 = trainy.iloc[train_idx2], trainy.iloc[test_idx2]\n",
    "        \n",
    "        trainX2=trainX2.drop('manager_skill',axis=1)\n",
    "        \n",
    "        temp = pd.concat([trainX2['manager_id'], pd.get_dummies(trainX2['interest_level'])],axis =1).groupby('manager_id').mean()\n",
    "        temp.columns = ['low_frac','medium_frac', 'high_frac']\n",
    "        #print(temp.head())\n",
    "        temp['count'] = trainX2.groupby('manager_id').count()\n",
    "\n",
    "        \n",
    "        temp['manager_skill'] = temp['high_frac']*2 + temp['medium_frac']\n",
    "        mean_skill = temp.loc[temp['count'] >= 5, 'manager_skill'].mean() # setting a thresold\n",
    "        temp.loc[temp['count'] < 2, 'manager_skill'] = mean_skill # if count is less than thresold impute the mean\n",
    "\n",
    "        testX2=testX2.drop('manager_skill',axis=1)\n",
    "        testX2 = testX2.merge(temp.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "        testX2['manager_skill'].fillna(mean_skill, inplace= True) # if manager_id is not found fill it by mean value\n",
    "      \n",
    "        trainX.iloc[list(test_idx2), trainX.columns.get_loc('manager_skill')] = list(testX2['manager_skill'])\n",
    "\n",
    "\n",
    "    testX=testX.drop('manager_skill',axis=1)\n",
    "    trainX=trainX.drop('interest_level',axis=1)\n",
    "    \n",
    "    temp2 = trainX.groupby('manager_id').mean()\n",
    "    testX = testX.merge(temp2.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "    testX['manager_skill'].fillna(testX['manager_skill'].dropna().mean(), inplace= True)\n",
    "    \n",
    "    train2.iloc[list(test_idx), train2.columns.get_loc('manager_skill')] = list(testX['manager_skill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['manager_skill'] = train2['manager_skill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use.append('manager_skill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.588127625952\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2= test_[['manager_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         manager_id  manager_skill\n",
      "0  b1b1852c416d78d7765d746cb1b8921f       0.800746\n",
      "1  d0b5648017832b2427eeb9956d966a14       0.000000\n",
      "2  9ca6f3baa475c37a3b3521a394d65467       0.390975\n",
      "3  0b9d5db96db8472d7aeb67c67338c4d2       1.090504\n",
      "4  b5eda0eb31b042ce2124fd9e9fcfce2f       0.482316\n"
     ]
    }
   ],
   "source": [
    "temp3 = train2.groupby('manager_id').mean()\n",
    "#print((temp3.head()))\n",
    "temp3 = temp3.drop('interest_level',axis=1)\n",
    "#print((temp3.head()))\n",
    "test2 = test2.merge(temp3.reset_index(),how='left', left_on='manager_id', right_on='manager_id')\n",
    "print(test2.head())\n",
    "test2['manager_skill'].fillna(test2['manager_skill'].dropna().mean(), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manager_id</th>\n",
       "      <th>manager_skill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1b1852c416d78d7765d746cb1b8921f</td>\n",
       "      <td>0.800746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d0b5648017832b2427eeb9956d966a14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9ca6f3baa475c37a3b3521a394d65467</td>\n",
       "      <td>0.390975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0b9d5db96db8472d7aeb67c67338c4d2</td>\n",
       "      <td>1.090504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b5eda0eb31b042ce2124fd9e9fcfce2f</td>\n",
       "      <td>0.482316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         manager_id  manager_skill\n",
       "0  b1b1852c416d78d7765d746cb1b8921f       0.800746\n",
       "1  d0b5648017832b2427eeb9956d966a14       0.000000\n",
       "2  9ca6f3baa475c37a3b3521a394d65467       0.390975\n",
       "3  0b9d5db96db8472d7aeb67c67338c4d2       1.090504\n",
       "4  b5eda0eb31b042ce2124fd9e9fcfce2f       0.482316"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1b1852c416d78d7765d746cb1b8921f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d0b5648017832b2427eeb9956d966a14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>9ca6f3baa475c37a3b3521a394d65467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0b9d5db96db8472d7aeb67c67338c4d2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>b5eda0eb31b042ce2124fd9e9fcfce2f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              manager_id\n",
       "0       b1b1852c416d78d7765d746cb1b8921f\n",
       "1       d0b5648017832b2427eeb9956d966a14\n",
       "100     9ca6f3baa475c37a3b3521a394d65467\n",
       "1000    0b9d5db96db8472d7aeb67c67338c4d2\n",
       "100000  b5eda0eb31b042ce2124fd9e9fcfce2f"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_[['manager_id']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['manager_skill'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-22643937236b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'manager_skill'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[0;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2161\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2163\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   3622\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[1;32m-> 3624\u001b[1;33m                                  labels[mask])\n\u001b[0m\u001b[0;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3626\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: labels ['manager_skill'] not contained in axis"
     ]
    }
   ],
   "source": [
    "test.drop('manager_skill', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['manager_skill'] = test2['manager_skill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['manager_skill'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train3 = train[['building_id','interest_level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shaurya\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Shaurya\\Anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "train3['building_value'] =np.nan\n",
    "\n",
    "for train_idx, test_idx in kfold3.split(train3):\n",
    "    trainX, testX = train3.iloc[train_idx], train3.iloc[test_idx]\n",
    "    trainy, testy = train_y.iloc[train_idx], train_y.iloc[test_idx]\n",
    "    \n",
    "\n",
    "    for train_idx2, test_idx2 in kfold3.split(trainX):\n",
    "        trainX2, testX2 = trainX.iloc[train_idx2], trainX.iloc[test_idx2]\n",
    "        trainy2, testy2 = trainy.iloc[train_idx2], trainy.iloc[test_idx2]\n",
    "\n",
    "        \n",
    "        trainX2=trainX2.drop('building_value',axis=1)\n",
    "        \n",
    "        temp = pd.concat([trainX2['building_id'], pd.get_dummies(trainX2['interest_level'])],axis =1).groupby('building_id').mean()\n",
    "        temp.columns = ['low_frac','medium_frac', 'high_frac']\n",
    "        #print(temp.head())\n",
    "        temp['count'] = trainX2.groupby('building_id').count()\n",
    "\n",
    "        \n",
    "        temp['building_value'] = temp['high_frac']*2 + temp['medium_frac']\n",
    "        mean_value = temp.loc[temp['count'] >= 5, 'building_value'].mean() # setting a thresold\n",
    "        temp.loc[temp['count'] < 2, 'building_value'] = mean_value # if count is less than thresold impute the mean\n",
    "\n",
    "        testX2=testX2.drop('building_value',axis=1)\n",
    "        testX2 = testX2.merge(temp.reset_index(),how='left', left_on='building_id', right_on='building_id')\n",
    "        testX2['building_value'].fillna(mean_skill, inplace= True) # if manager_id is not found fill it by mean value\n",
    "      \n",
    "        trainX.iloc[list(test_idx2), trainX.columns.get_loc('building_value')] = list(testX2['building_value'])\n",
    "\n",
    "\n",
    "    testX=testX.drop('building_value',axis=1)\n",
    "    trainX=trainX.drop('interest_level',axis=1)\n",
    "    \n",
    "    temp2 = trainX.groupby('building_id').mean()\n",
    "    testX = testX.merge(temp2.reset_index(),how='left', left_on='building_id', right_on='building_id')\n",
    "    testX['building_value'].fillna(testX['building_value'].dropna().mean(), inplace= True)\n",
    "    \n",
    "    train3.iloc[list(test_idx), train3.columns.get_loc('building_value')] = list(testX['building_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['building_value'] = train3['building_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use.append('building_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.577978172591\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test3= test[['building_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp4 = train3.groupby('building_id').mean()\n",
    "test3 = test3.merge(temp4.reset_index(),how='left', left_on='building_id', right_on='building_id')\n",
    "test3['building_value'].fillna(testX['building_value'].dropna().mean(), inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['building_value'] = test3['building_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['building_value'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "categorical = [\"display_address\", \"manager_id\", \"building_id\", \"street_address\"]\n",
    "for f in categorical:\n",
    "        if train[f].dtype=='object':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "            train[f] = lbl.transform(train[f].values)\n",
    "            test[f] = lbl.transform(test[f].values)\n",
    "            features_to_use.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Check the performance after using magic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.576855551283\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating text count as a feature(But it doesn't improve the performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "\n",
    "tfidf = CountVectorizer(stop_words='english', max_features=200)\n",
    "train_sparse = tfidf.fit_transform(train[\"clean_description\"])\n",
    "test_sparse = tfidf.transform(test[\"clean_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "train_X = sparse.hstack([train[features_to_use], train_sparse]).tocsr()\n",
    "#test_X = sparse.hstack([test[features_to_use], test_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_X.toarray()\n",
    "#test_X = test_X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.576854680343\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfdesc=TfidfVectorizer(min_df=10, max_features=50)\n",
    "train_sparsed = tfidfdesc.fit_transform(train[\"clean_description\"])\n",
    "#test_sparsed = tfidfdesc.transform(test[\"clean_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X2 = sparse.hstack([train[features_to_use], train_sparsed]).tocsr()\n",
    "#test_X2 = sparse.hstack([test2[features_to_use], test_sparsed]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X2 = train_X2.toarray()\n",
    "#test_X2 = test_X2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.576860161965\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X3 = sparse.hstack([train[features_to_use], train_sparse,train_sparsed]).tocsr()#\\\n",
    "#test_X3 = sparse.hstack([test2[features_to_use], test_sparse,test_sparsed]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X3 = train_X3.toarray()\n",
    "#test_X3 = test_X3.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.578075546664\n"
     ]
    }
   ],
   "source": [
    "results = model_selection.cross_val_score(model4,train_X, train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using different models for the predictions and mentioning the Log-loss of each model on Leader Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "rf1 = RandomForestClassifier(criterion='entropy',  n_jobs = -1,  random_state=random_state)\n",
    "rf2= RandomForestClassifier( criterion='gini',  n_jobs = -1, random_state=random_state)\n",
    "gbc = GradientBoostingClassifier(random_state=random_state)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('rf1', rf1), ('rf2', rf2), ('gbc', gbc)], voting='soft')\n",
    "eclf.fit(train[features_to_use], train_y)\n",
    "y_pred_test =eclf.predict_proba(test[features_to_use])          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'high': 2, 'low': 0, 'medium': 1}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels2idx = {'low': 0, 'medium': 1, 'high': 2}\n",
    "labels2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.58986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eclf2 = VotingClassifier(estimators=[('rf1', rf1), ('rf2', rf2), ('gbc', gbc)], voting='soft', weights = [1,1,3])\n",
    "eclf2.fit(train[features_to_use], train_y)\n",
    "y_pred_test2 =eclf2.predict_proba(test[features_to_use])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test2[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.58005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier , ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.06498336496\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model5 = AdaBoostClassifier()\n",
    "results = model_selection.cross_val_score(model5, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.50425540146\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model5 = ExtraTreesClassifier()\n",
    "results = model_selection.cross_val_score(model5, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.555059922796\n"
     ]
    }
   ],
   "source": [
    "random_state = 54321\n",
    "dt = DecisionTreeClassifier(min_samples_leaf= 500)\n",
    "rf12 = RandomForestClassifier(criterion='entropy',n_estimators=400, max_features= 'sqrt',  n_jobs = -1)\n",
    "rf22= RandomForestClassifier( criterion='gini',n_estimators=300, max_features= 'sqrt', n_jobs = -1)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf13 = VotingClassifier(estimators=[('dt',dt),('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft', weights = [1,1,1,3,3])\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "results = model_selection.cross_val_score(eclf13, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())\n",
    "#eclf12.fit(train[features_to_use], train_y)\n",
    "#y_pred_test12 =eclf12.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eclf13.fit(train[features_to_use], train_y)\n",
    "y_pred_test13 =eclf13.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test13[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf13.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "adc = AdaBoostClassifier(random_state=random_state)\n",
    "extc = ExtraTreesClassifier(random_state=random_state)\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=[('rf1', rf1), ('rf2', rf2), ('gbc', gbc), ('adc', adc), ('extc', extc)], \n",
    "                         voting='soft', weights = [1,1,4,1,1])\n",
    "\n",
    "eclf3.fit(train[features_to_use], train_y)\n",
    "y_pred_test3 =eclf.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test3[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5719469538\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10,  random_state=seed)\n",
    "model_a = RandomForestClassifier(criterion='gini' , n_estimators=300, max_features= 'sqrt')\n",
    "results = model_selection.cross_val_score(model_a, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.568437783474\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10,  random_state=seed)\n",
    "model_b = RandomForestClassifier(criterion='entropy' , n_estimators=400, max_features= 'sqrt')\n",
    "results = model_selection.cross_val_score(model_b, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.555977146749\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10,  random_state=seed)\n",
    "model_c = GradientBoostingClassifier(n_estimators=500)\n",
    "results = model_selection.cross_val_score(model_c, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.556619530533\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10,  random_state=seed)\n",
    "model_d = GradientBoostingClassifier( n_estimators=450)\n",
    "results = model_selection.cross_val_score(model_d, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.555350287445\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model_xgb = XGBClassifier(n_estimators=500)\n",
    "results = model_selection.cross_val_score(model_xgb, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.62488310256\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model5 = DecisionTreeClassifier(min_samples_leaf= 500)\n",
    "results = model_selection.cross_val_score(model5, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "rf12 = RandomForestClassifier(criterion='entropy',n_estimators=400, max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini',  n_estimators=300, max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "\n",
    "eclf4 = VotingClassifier(estimators=[('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2)], voting='soft')\n",
    "eclf4.fit(train[features_to_use], train_y)\n",
    "y_pred_test4 =eclf4.predict_proba(test[features_to_use])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test4[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56684"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "rf12 = RandomForestClassifier(criterion='entropy',n_estimators=400, max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini',  n_estimators=300, max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf6 = VotingClassifier(estimators=[('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft')\n",
    "eclf6.fit(train[features_to_use], train_y)\n",
    "y_pred_test6 =eclf6.predict_proba(test[features_to_use]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test6[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "rf12 = RandomForestClassifier(criterion='entropy',n_estimators=400, max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini',  n_estimators=300, max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "\n",
    "eclf5 = VotingClassifier(estimators=[('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2)], voting='soft', weights = [1,1,3])\n",
    "eclf5.fit(train[features_to_use], train_y)\n",
    "y_pred_test5 =eclf5.predict_proba(test[features_to_use])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test5[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56210"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "rf12 = RandomForestClassifier(criterion='entropy',n_estimators=400, max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini',  n_estimators=300, max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf7 = VotingClassifier(estimators=[('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft', weights = [1,1,3,3])\n",
    "eclf7.fit(train[features_to_use], train_y)\n",
    "y_pred_test =eclf7.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56079"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "rf12 = RandomForestClassifier(criterion='entropy',n_estimators=400, max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini',  n_estimators=300, max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf8 = VotingClassifier(estimators=[('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft', weights = [1,1,1,3])\n",
    "eclf8.fit(train[features_to_use], train_y)\n",
    "y_pred_test8 =eclf8.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test8[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "rf12 = RandomForestClassifier(criterion='entropy', max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini', max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf9 = VotingClassifier(estimators=[('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft', weights = [1,1,1,3])\n",
    "eclf9.fit(train[features_to_use], train_y)\n",
    "y_pred_test9 =eclf9.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test9[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf9.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "dt = DecisionTreeClassifier(random_state=random_state)\n",
    "rf12 = RandomForestClassifier(criterion='entropy', max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini', max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf10 = VotingClassifier(estimators=[('dt',dt),('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft', weights = [1,1,1,1,3])\n",
    "eclf10.fit(train[features_to_use], train_y)\n",
    "y_pred_test10 =eclf10.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test10[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.57536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "dt = DecisionTreeClassifier(random_state=random_state)\n",
    "rf12 = RandomForestClassifier(criterion='entropy', max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini', max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf11 = VotingClassifier(estimators=[('dt',dt),('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft', weights = [1,1,1,3,3])\n",
    "eclf11.fit(train[features_to_use], train_y)\n",
    "y_pred_test11 =eclf11.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test11[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "dt = DecisionTreeClassifier(random_state=random_state)\n",
    "rf12 = RandomForestClassifier(criterion='entropy',n_estimators=400, max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini',n_estimators=300, max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf12 = VotingClassifier(estimators=[('dt',dt),('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft', weights = [1,1,1,3,3])\n",
    "eclf12.fit(train[features_to_use], train_y)\n",
    "y_pred_test12 =eclf12.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test12[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf12.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stacking and ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 10 # set folds for out-of-fold prediction\n",
    "kf5 = model_selection.KFold( n_splits= NFOLDS, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf1_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 400,\n",
    "    \"criterion\":'entropy',\n",
    "    'max_features' : 'sqrt'\n",
    "}\n",
    "\n",
    "# Random Forest parameters\n",
    "rf2_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators':300,\n",
    "    'max_features' : 'sqrt',\n",
    "    'criterion' :'gini'\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 450\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf5.split(train[features_to_use])):\n",
    "        x_tr = x_train.iloc[train_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        x_te = x_train.iloc[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_basemodel_1 = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf1_params)\n",
    "rf_basemodel_2 = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf2_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train[features_to_use] # Creates an array of the train data\n",
    "x_test = test[features_to_use] # Creats an array of the test data\n",
    "y_train =train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1_oof_train, rf1_oof_test = get_oof(rf_basemodel_1,x_train, y_train, x_test) # Random Forest1\n",
    "rf2_oof_train, rf2_oof_test = get_oof(rf_basemodel_2,x_train, y_train, x_test) # Random Forest2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 1)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1_oof_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 1)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1_oof_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0057872   0.00785919  0.05311362  0.05460172  0.08334348  0.05313182\n",
      "  0.01878873  0.          0.039833    0.03920931  0.05682042  0.05209093\n",
      "  0.00957201  0.05594686  0.15865577  0.09835107  0.05227153  0.04881335\n",
      "  0.05915259  0.05265739]\n",
      "[ 0.00570351  0.00803992  0.05320849  0.05439168  0.08150379  0.05546506\n",
      "  0.01884059  0.          0.04029595  0.03825217  0.05708406  0.0505135\n",
      "  0.00968644  0.05630707  0.15637819  0.09947278  0.05313319  0.04923369\n",
      "  0.05964939  0.05284051]\n"
     ]
    }
   ],
   "source": [
    "rf1_feature = rf_basemodel_1.feature_importances(x_train,y_train)\n",
    "rf2_feature = rf_basemodel_2.feature_importances(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1_features = [ 0.0057872,   0.00785919,  0.05311362,  0.05460172,  0.08334348,  0.05313182,\n",
    "  0.01878873,  0.0,          0.039833,    0.03920931,  0.05682042,  0.05209093,\n",
    "  0.00957201,  0.05594686,  0.15865577,  0.09835107,  0.05227153,  0.04881335,\n",
    "  0.05915259,  0.05265739]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf2_features = [ 0.00570351,  0.00803992,  0.05320849,  0.05439168,  0.08150379,  0.05546506,\n",
    "  0.01884059,  0.0,          0.04029595,  0.03825217,  0.05708406,  0.0505135,\n",
    "  0.00968644,  0.05630707,  0.15637819,  0.09947278,  0.05313319,  0.04923369,\n",
    "  0.05964939,  0.05284051]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a dataframe with features\n",
    "feature_dataframe = pd.DataFrame( {'features': features_to_use,\n",
    "     'Random Forest_1 feature importances': rf1_features,\n",
    "    'Random Forest_2 feature importances': rf2_features                            \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest_1 feature importances</th>\n",
       "      <th>Random Forest_2 feature importances</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>bathrooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>bedrooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.053208</td>\n",
       "      <td>latitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054602</td>\n",
       "      <td>0.054392</td>\n",
       "      <td>longitude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083343</td>\n",
       "      <td>0.081504</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.053132</td>\n",
       "      <td>0.055465</td>\n",
       "      <td>created_day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.018789</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>created_month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>created_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.039833</td>\n",
       "      <td>0.040296</td>\n",
       "      <td>num_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.039209</td>\n",
       "      <td>0.038252</td>\n",
       "      <td>num_photos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.056820</td>\n",
       "      <td>0.057084</td>\n",
       "      <td>description_length</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.052091</td>\n",
       "      <td>0.050514</td>\n",
       "      <td>price_t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009572</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>room_sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.055947</td>\n",
       "      <td>0.056307</td>\n",
       "      <td>price_per_room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.158656</td>\n",
       "      <td>0.156378</td>\n",
       "      <td>manager_skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.098351</td>\n",
       "      <td>0.099473</td>\n",
       "      <td>building_value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.052272</td>\n",
       "      <td>0.053133</td>\n",
       "      <td>display_address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.048813</td>\n",
       "      <td>0.049234</td>\n",
       "      <td>manager_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.059153</td>\n",
       "      <td>0.059649</td>\n",
       "      <td>building_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.052657</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>street_address</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Random Forest_1 feature importances  Random Forest_2 feature importances  \\\n",
       "0                              0.005787                             0.005704   \n",
       "1                              0.007859                             0.008040   \n",
       "2                              0.053114                             0.053208   \n",
       "3                              0.054602                             0.054392   \n",
       "4                              0.083343                             0.081504   \n",
       "5                              0.053132                             0.055465   \n",
       "6                              0.018789                             0.018841   \n",
       "7                              0.000000                             0.000000   \n",
       "8                              0.039833                             0.040296   \n",
       "9                              0.039209                             0.038252   \n",
       "10                             0.056820                             0.057084   \n",
       "11                             0.052091                             0.050514   \n",
       "12                             0.009572                             0.009686   \n",
       "13                             0.055947                             0.056307   \n",
       "14                             0.158656                             0.156378   \n",
       "15                             0.098351                             0.099473   \n",
       "16                             0.052272                             0.053133   \n",
       "17                             0.048813                             0.049234   \n",
       "18                             0.059153                             0.059649   \n",
       "19                             0.052657                             0.052841   \n",
       "\n",
       "              features  \n",
       "0            bathrooms  \n",
       "1             bedrooms  \n",
       "2             latitude  \n",
       "3            longitude  \n",
       "4                price  \n",
       "5          created_day  \n",
       "6        created_month  \n",
       "7         created_year  \n",
       "8         num_features  \n",
       "9           num_photos  \n",
       "10  description_length  \n",
       "11             price_t  \n",
       "12            room_sum  \n",
       "13      price_per_room  \n",
       "14       manager_skill  \n",
       "15      building_value  \n",
       "16     display_address  \n",
       "17          manager_id  \n",
       "18         building_id  \n",
       "19      street_address  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest_1 feature importances</th>\n",
       "      <th>Random Forest_2 feature importances</th>\n",
       "      <th>features</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.158656</td>\n",
       "      <td>0.156378</td>\n",
       "      <td>manager_skill</td>\n",
       "      <td>0.157517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.098351</td>\n",
       "      <td>0.099473</td>\n",
       "      <td>building_value</td>\n",
       "      <td>0.098912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.083343</td>\n",
       "      <td>0.081504</td>\n",
       "      <td>price</td>\n",
       "      <td>0.082424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.059153</td>\n",
       "      <td>0.059649</td>\n",
       "      <td>building_id</td>\n",
       "      <td>0.059401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.056820</td>\n",
       "      <td>0.057084</td>\n",
       "      <td>description_length</td>\n",
       "      <td>0.056952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.055947</td>\n",
       "      <td>0.056307</td>\n",
       "      <td>price_per_room</td>\n",
       "      <td>0.056127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054602</td>\n",
       "      <td>0.054392</td>\n",
       "      <td>longitude</td>\n",
       "      <td>0.054497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.053132</td>\n",
       "      <td>0.055465</td>\n",
       "      <td>created_day</td>\n",
       "      <td>0.054298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053114</td>\n",
       "      <td>0.053208</td>\n",
       "      <td>latitude</td>\n",
       "      <td>0.053161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.052657</td>\n",
       "      <td>0.052841</td>\n",
       "      <td>street_address</td>\n",
       "      <td>0.052749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.052272</td>\n",
       "      <td>0.053133</td>\n",
       "      <td>display_address</td>\n",
       "      <td>0.052702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.052091</td>\n",
       "      <td>0.050514</td>\n",
       "      <td>price_t</td>\n",
       "      <td>0.051302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.048813</td>\n",
       "      <td>0.049234</td>\n",
       "      <td>manager_id</td>\n",
       "      <td>0.049024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.039833</td>\n",
       "      <td>0.040296</td>\n",
       "      <td>num_features</td>\n",
       "      <td>0.040064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.039209</td>\n",
       "      <td>0.038252</td>\n",
       "      <td>num_photos</td>\n",
       "      <td>0.038731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.018789</td>\n",
       "      <td>0.018841</td>\n",
       "      <td>created_month</td>\n",
       "      <td>0.018815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009572</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>room_sum</td>\n",
       "      <td>0.009629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>bedrooms</td>\n",
       "      <td>0.007950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.005704</td>\n",
       "      <td>bathrooms</td>\n",
       "      <td>0.005745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>created_year</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Random Forest_1 feature importances  Random Forest_2 feature importances  \\\n",
       "14                             0.158656                             0.156378   \n",
       "15                             0.098351                             0.099473   \n",
       "4                              0.083343                             0.081504   \n",
       "18                             0.059153                             0.059649   \n",
       "10                             0.056820                             0.057084   \n",
       "13                             0.055947                             0.056307   \n",
       "3                              0.054602                             0.054392   \n",
       "5                              0.053132                             0.055465   \n",
       "2                              0.053114                             0.053208   \n",
       "19                             0.052657                             0.052841   \n",
       "16                             0.052272                             0.053133   \n",
       "11                             0.052091                             0.050514   \n",
       "17                             0.048813                             0.049234   \n",
       "8                              0.039833                             0.040296   \n",
       "9                              0.039209                             0.038252   \n",
       "6                              0.018789                             0.018841   \n",
       "12                             0.009572                             0.009686   \n",
       "1                              0.007859                             0.008040   \n",
       "0                              0.005787                             0.005704   \n",
       "7                              0.000000                             0.000000   \n",
       "\n",
       "              features      mean  \n",
       "14       manager_skill  0.157517  \n",
       "15      building_value  0.098912  \n",
       "4                price  0.082424  \n",
       "18         building_id  0.059401  \n",
       "10  description_length  0.056952  \n",
       "13      price_per_room  0.056127  \n",
       "3            longitude  0.054497  \n",
       "5          created_day  0.054298  \n",
       "2             latitude  0.053161  \n",
       "19      street_address  0.052749  \n",
       "16     display_address  0.052702  \n",
       "11             price_t  0.051302  \n",
       "17          manager_id  0.049024  \n",
       "8         num_features  0.040064  \n",
       "9           num_photos  0.038731  \n",
       "6        created_month  0.018815  \n",
       "12            room_sum  0.009629  \n",
       "1             bedrooms  0.007950  \n",
       "0            bathrooms  0.005745  \n",
       "7         created_year  0.000000  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\n",
    "feature_dataframe.sort_values(by='mean' ,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest1</th>\n",
       "      <th>RandomForest2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RandomForest1  RandomForest2\n",
       "0            0.0            0.0\n",
       "1            0.0            0.0\n",
       "2            1.0            1.0\n",
       "3            0.0            0.0\n",
       "4            0.0            0.0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_predictions_train = pd.DataFrame( {'RandomForest1': rf1_oof_train.ravel(),\n",
    "     'RandomForest2': rf2_oof_train.ravel()\n",
    "    })\n",
    "base_predictions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate((  rf1_oof_train, rf2_oof_train ), axis=1)\n",
    "x_test = np.concatenate((  rf1_oof_test, rf2_oof_test ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49352, 2)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74659, 2)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc_stack = GradientBoostingClassifier( random_state=random_state)\n",
    "gbc_stack.fit(x_train, y_train)\n",
    "predictions = gbc_stack.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = predictions[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_stack1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28288313,  0.51214877,  0.20496811],\n",
       "       [ 0.81696696,  0.15856797,  0.02446507],\n",
       "       [ 0.81696696,  0.15856797,  0.02446507],\n",
       "       ..., \n",
       "       [ 0.81696696,  0.15856797,  0.02446507],\n",
       "       [ 0.28288313,  0.51214877,  0.20496811],\n",
       "       [ 0.81696696,  0.15856797,  0.02446507]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Some more features to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ = pd.read_json('train.json')\n",
    "test_ = pd.read_json('test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'metropolitan avenue'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_['display_address'][10].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'792 Metropolitan Avenue'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_['street_address'] [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Levenshtein.ratio(train_['display_address'][10].lower(), train_['street_address'] [10].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leven_ratio_row(row):\n",
    "    return Levenshtein.ratio(row.display_address.lower(), row.street_address.lower())\n",
    "\n",
    "def get_leven_ratio(df):\n",
    "    return df.apply(get_leven_ratio_row, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['address_ratio'] =get_leven_ratio(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['address_ratio'] =get_leven_ratio(test_).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['address_ratio'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_to_use.append('address_ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.553786014577\n"
     ]
    }
   ],
   "source": [
    "random_state = 54321\n",
    "dt = DecisionTreeClassifier(min_samples_leaf= 500)\n",
    "rf12 = RandomForestClassifier(criterion='entropy',n_estimators=400, max_features= 'sqrt',  n_jobs = -1)\n",
    "rf22= RandomForestClassifier( criterion='gini',n_estimators=300, max_features= 'sqrt', n_jobs = -1)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf14 = VotingClassifier(estimators=[('dt',dt),('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft', weights = [1,1,1,3,3])\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "results = model_selection.cross_val_score(eclf14, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eclf14.fit(train[features_to_use], train_y)\n",
    "y_pred_test14 =eclf14.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test14[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf14.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_state = 54321\n",
    "rf12 = RandomForestClassifier(criterion='entropy',n_estimators=400, max_features= 'sqrt',  n_jobs = -1,  random_state=random_state)\n",
    "rf22= RandomForestClassifier( criterion='gini',  n_estimators=300, max_features= 'sqrt', n_jobs = -1, random_state=random_state)\n",
    "gbc2 = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "xgb = XGBClassifier(n_estimators=500)\n",
    "\n",
    "eclf15 = VotingClassifier(estimators=[('rf12', rf12), ('rf22', rf22), ('gbc2', gbc2), ('xgb', xgb)], voting='soft', weights = [1,1,3,3])\n",
    "eclf15.fit(train[features_to_use], train_y)\n",
    "y_pred_test15 =eclf15.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test15[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_eclf15.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.06586045927\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model8 = AdaBoostClassifier()\n",
    "results = model_selection.cross_val_score(model8, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.705734073619\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model8 = AdaBoostClassifier(n_estimators= 100, learning_rate= 0.001)\n",
    "results = model_selection.cross_val_score(model8, train[features_to_use], train_y, cv=kfold, scoring = 'neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc_model = GradientBoostingClassifier(n_estimators=450, random_state=random_state)\n",
    "gbc_model.fit(train[features_to_use], train_y)\n",
    "y_pred_test16 = gbc_model.predict_proba(test[features_to_use])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub[\"listing_id\"] = test[\"listing_id\"]\n",
    "for label in [\"high\", \"medium\", \"low\"]:\n",
    "    sub[label] = y_pred_test16[:, labels2idx[label]]\n",
    "sub.to_csv(\"submission3_gbcmodel.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LB : 0.56712"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
